{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec82917-9929-4ede-8843-c57a50d603fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters: {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'bootstrap': True}\n",
      "Optimiertes Model MAE: 4.47\n",
      "Optimiertes Model RMSE: 14.19\n",
      "Optimiertes R²: 0.79\n",
      "Custom Loss on Test Set: 1862.52\n",
      "Custom Loss Cross-Validation Scores: [-1386.642      -2256.834      -1732.987      -1890.776\n",
      "  -977.25442857]\n",
      "Mean Custom Loss: -1648.90\n",
      "Feature Importances:\n",
      "          feature  importance\n",
      "0  calls_per_duty    0.909906\n",
      "1       month_sin    0.031155\n",
      "3            year    0.029035\n",
      "4     day_of_week    0.015975\n",
      "2       month_cos    0.013930\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Lädt die Daten aus einer CSV-Datei.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def load_splits(X_train_path, X_test_path, y_train_path, y_test_path):\n",
    "    \"\"\"Lädt die gespeicherten Trainings- und Testdaten.\"\"\"\n",
    "    X_train = pd.read_csv(X_train_path)\n",
    "    X_test = pd.read_csv(X_test_path)\n",
    "    y_train = pd.read_csv(y_train_path).values.ravel()  # ravel() konvertiert DataFrame in 1D-Array\n",
    "    y_test = pd.read_csv(y_test_path).values.ravel()\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def feature_engineering(data):\n",
    "    \"\"\"Erstellt Interaktionsvariablen und lagged features.\"\"\"\n",
    "    data['calls_per_duty_lag7'] = data['calls_per_duty'].shift(7)\n",
    "    data['avg_sick_last_30_days_lag7'] = data['avg_sick_last_30_days'].shift(7)\n",
    "    data['interaction_term'] = data['calls_per_duty'] * data['avg_sick_last_30_days']\n",
    "    return data.dropna()\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"Berechnet eine benutzerdefinierte Verlustfunktion.\"\"\"\n",
    "    under_estimation = (y_true > y_pred) * (y_true - y_pred)\n",
    "    over_estimation = (y_pred > y_true) * (y_pred - y_true)\n",
    "    loss = 3 * under_estimation + over_estimation  # Faktor 3 für Unterdeckung\n",
    "    return loss.sum()\n",
    "\n",
    "def train_random_forest(X_train, y_train, param_dist):\n",
    "    \"\"\"Trainiert ein Random Forest Modell mit Hyperparameter-Optimierung.\"\"\"\n",
    "    custom_scorer = make_scorer(custom_loss, greater_is_better=False)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    rf_random = RandomizedSearchCV(\n",
    "        estimator=RandomForestRegressor(random_state=42),\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,\n",
    "        cv=tscv,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        scoring=custom_scorer\n",
    "    )\n",
    "    \n",
    "    rf_random.fit(X_train, y_train)\n",
    "    return rf_random.best_estimator_, rf_random.best_params_\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Bewertet das Modell und gibt MAE, RMSE und benutzerdefinierte Verlustfunktion zurück.\"\"\"\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    custom_loss_value = custom_loss(y_test, predictions)\n",
    "    return mae, rmse, r2, custom_loss_value\n",
    "\n",
    "def save_model(model, path):\n",
    "    \"\"\"Speichert das trainierte Modell in einer Datei.\"\"\"\n",
    "    joblib.dump(model, path)\n",
    "\n",
    "def main():\n",
    "    # Dateipfade\n",
    "    input_file_path = r\"..\\data\\processed_data\\preprocessed_data.csv\"\n",
    "    model_save_path = r\"..\\models\\fortgeschrittenes_model.pkl\"\n",
    "    \n",
    "    # Pfade zu den gespeicherten Trainings- und Testdatensätzen\n",
    "    X_train_path = r\"..\\data\\X_train.csv\"\n",
    "    X_test_path = r\"..\\data\\X_test.csv\"\n",
    "    y_train_path = r\"..\\data\\y_train.csv\"\n",
    "    y_test_path = r\"..\\data\\y_test.csv\"\n",
    "\n",
    "    # Daten einlesen\n",
    "    data = load_data(input_file_path)\n",
    "\n",
    "    # Feature Engineering\n",
    "    data = feature_engineering(data)\n",
    "\n",
    "    # Feature- und Zielvariablen festlegen\n",
    "    features = ['calls_per_duty', 'month_sin', 'month_cos', 'year', 'day_of_week']\n",
    "    target = 'adjusted_need_cleaned'\n",
    "\n",
    "    # Gespeicherte Trainings- und Testdaten laden\n",
    "    X_train, X_test, y_train, y_test = load_splits(X_train_path, X_test_path, y_train_path, y_test_path)\n",
    "\n",
    "    # Hyperparameter für RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 500, 1000],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Random Forest Modell trainieren\n",
    "    best_rf, best_params = train_random_forest(X_train, y_train, param_dist)\n",
    "    print(f'Best Parameters: {best_params}')\n",
    "\n",
    "    # Vorhersagen und Metriken berechnen\n",
    "    mae, rmse, r2, custom_loss_value = evaluate_model(best_rf, X_test, y_test)\n",
    "    print(f'Optimiertes Model MAE: {mae:.2f}')\n",
    "    print(f'Optimiertes Model RMSE: {rmse:.2f}')\n",
    "    print(f'Optimiertes R²: {r2:.2f}')\n",
    "    print(f'Custom Loss on Test Set: {custom_loss_value:.2f}')\n",
    "\n",
    "    # Cross-Validation mit TimeSeriesSplit und benutzerdefinierter Verlustfunktion\n",
    "    cross_val_scores = cross_val_score(best_rf, X_train, y_train, cv=TimeSeriesSplit(n_splits=5), scoring=make_scorer(custom_loss, greater_is_better=False))\n",
    "    print(f'Custom Loss Cross-Validation Scores: {cross_val_scores}')\n",
    "    print(f'Mean Custom Loss: {np.mean(cross_val_scores):.2f}')\n",
    "\n",
    "    # Feature-Importances\n",
    "    importances = best_rf.feature_importances_\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': importances\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "    print(\"Feature Importances:\")\n",
    "    print(feature_importances)\n",
    "\n",
    "    # Modell speichern\n",
    "    save_model(best_rf, model_save_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da726387-77f2-4a76-a2d4-e834a13eecd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de153ff5-ed0e-4bff-9bbb-da8c37885d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
